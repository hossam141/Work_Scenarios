# ğŸ“Œ Troubleshooting Kubernetes Applications & Connectivity Issues

## **ğŸ”¹ Understanding Kubernetes Pod Status**
A Kubernetes pod can enter different states based on its lifecycle and issues encountered during execution. Below are common pod states:

| **Pod Status** | **Description** |
|--------------|---------------|
| **Pending** | The pod has been accepted by the cluster but is waiting for resource allocation. |
| **Running** | The pod has been scheduled on a node and all containers are running. |
| **Succeeded** | The pod has completed execution successfully (used in Jobs). |
| **Failed** | One or more containers in the pod terminated with an error. |
| **CrashLoopBackOff** | A container is repeatedly crashing and restarting. |
| **ImagePullBackOff** | Kubernetes failed to pull the container image. |
| **Init:Error** | The `initContainer` failed to execute properly. |
| **ContainerCreating** | Kubernetes is pulling the image or mounting volumes before starting the container. |

---

## **ğŸ”¹ Troubleshooting Scenarios & Pod Status**

### **1ï¸âƒ£ Scenario: InitContainer (`Liquibase` for JAVA app) Fails**
### **ğŸš€ Issue:**
- `kubectl get pods` shows the pod stuck in **`Init:Error`** or `CrashLoopBackOff`.
- The InitContainer fails before the main application starts.

### **ğŸ›  Possible Causes & Fixes**
1ï¸âƒ£ **Check InitContainer Logs for Errors**
```bash
kubectl logs <pod-name> -c <init-container-name>
```
âœ… Look for database connectivity issues, permission errors, or missing migrations.

2ï¸âƒ£ **Verify Database Connection**
```bash
kubectl exec -it <pod-name> -- /bin/sh
nc -zv <db-host> <db-port>
```
âœ… Ensure Liquibase can reach the database.

3ï¸âƒ£ **Check InitContainer Command & Exit Code**
```bash
kubectl describe pod <pod-name>
```
âœ… Ensure the command executed successfully (`exit code 0`).

---

### **2ï¸âƒ£ Scenario: Secret Not Sealed Correctly & Mounted in Deployment**
### **ğŸš€ Issue:**
- `kubectl get pods` shows the pod stuck in **`CrashLoopBackOff`** or **`ContainerCreating`**.
- The application fails due to missing environment variables or mounted secrets.

### **ğŸ›  Possible Causes & Fixes**
1ï¸âƒ£ **Check Pod Events for Mounting Issues**
```bash
kubectl describe pod <pod-name>
```
âœ… Look for messages like `MountVolume.SetUp failed for volume`.

2ï¸âƒ£ **Verify Secret Exists**
```bash
kubectl get secret <secret-name> -o yaml
```
âœ… Ensure the secret is properly created and available.

3ï¸âƒ£ **Confirm Deployment is Correctly Mounting the Secret**
```yaml
volumes:
  - name: app-secret
    secret:
      secretName: my-secret
```
âœ… Ensure the secret name matches the Kubernetes resource.

---

### **3ï¸âƒ£ Scenario: Missing ConfigMap in Deployment**
### **ğŸš€ Issue:**
- `kubectl get pods` shows the pod in **`CrashLoopBackOff`** or **`ContainerCreating`** state.
- The application fails due to missing configuration files.

### **ğŸ›  Possible Causes & Fixes**
1ï¸âƒ£ **Check Pod Events for ConfigMap Issues**
```bash
kubectl describe pod <pod-name>
```
âœ… Look for `MountVolume.SetUp failed for volume` errors.

2ï¸âƒ£ **Verify ConfigMap Exists**
```bash
kubectl get configmap <configmap-name> -o yaml
```
âœ… Ensure the ConfigMap exists and contains the required values.

3ï¸âƒ£ **Confirm Deployment References the Correct ConfigMap Name**
```yaml
volumes:
  - name: app-config
    configMap:
      name: my-config
```
âœ… Ensure the ConfigMap name matches what is defined in the deployment.

---

### **4ï¸âƒ£ Scenario: Readiness or Liveness Probe Issues**
### **ğŸš€ Issue:**
- `kubectl get pods` shows the pod in **`Running`** state, but the app is unreachable.
- `kubectl describe pod <pod-name>` shows **liveness probe failures**.

### **ğŸ›  Possible Causes & Fixes**
1ï¸âƒ£ **Check Readiness & Liveness Probe Logs**
```bash
kubectl describe pod <pod-name>
```
âœ… Look for errors related to failed health checks.

2ï¸âƒ£ **Test Application Health Check Manually**
```bash
kubectl exec -it <pod-name> -- curl http://localhost:8080/health
```
âœ… Ensure the endpoint returns a **200 OK** response.

3ï¸âƒ£ **Fix Incorrect Probe Configurations**
```yaml
livenessProbe:
  httpGet:
    path: /health
    port: 8080
  initialDelaySeconds: 10
  periodSeconds: 5
```
âœ… Ensure the app has enough startup time before running the probe.

---

## **ğŸš€ Summary: Common Kubernetes Troubleshooting Scenarios & Pod Status**
| **Scenario** | **Issue** | **Pod Status** | **Solution** |
|-------------|---------|-----------|------------|
| **InitContainer (`Liquibase`) failure** | Database connection issues, migration failure | `Init:Error`, `CrashLoopBackOff` | Check logs, validate DB connection, fix init script |
| **Secret not mounted correctly** | Incorrectly sealed or missing secret | `CrashLoopBackOff`, `ContainerCreating` | Verify secret exists, check volume mounts |
| **Missing ConfigMap in Deployment** | ConfigMap not found or misconfigured | `CrashLoopBackOff`, `ContainerCreating` | Ensure ConfigMap exists, update deployment YAML |
| **Readiness/Liveness Probe failure** | Health check failures | `Running`, but failing probes | Check probe logs, increase `initialDelaySeconds`, validate endpoint |

âœ… **By following these troubleshooting steps, an SRE engineer can quickly diagnose and resolve Kubernetes failures!** ğŸš€
